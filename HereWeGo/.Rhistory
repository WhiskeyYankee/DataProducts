mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl)
summary(mpg.lm3)
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs)
summary(mpg.lm3)
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs-carb)
summary(mpg.lm3)
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs-carb-gear)
summary(mpg.lm3)
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs-carb-gear-drat)
summary(mpg.lm3)
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs-carb-gear-drat-disp)
summary(mpg.lm3)
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs-carb-gear-drat-disp-hp)
summary(mpg.lm3)
backSelection <-data.frame(
Model = c("Model1"),
Least_Significant_Predictor = c("cyl","vs","carb","gear","drat","disp","hp","Intercept"),
Predictor_Pvalue = c(0.9161, 0.8433,0.7470,0.6196, 0.4624,0.2989,0.2230,0.1779),
Model_R2 = c(0.8066,0.8153,0.8230,0.8296,0.8347,0.8375,0.8368,0.8336)
)
backSelection
backSelection <-data.frame(
Model = c("Model1","Model2","Model3","Model4","Model5","Model6","Model7","Model8"),
Least_Significant_Predictor = c("cyl","vs","carb","gear","drat","disp","hp","Intercept"),
Predictor_Pvalue = c(0.9161, 0.8433,0.7470,0.6196, 0.4624,0.2989,0.2230,0.1779),
Model_R2 = c(0.8066,0.8153,0.8230,0.8296,0.8347,0.8375,0.8368,0.8336)
)
backSelection
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs-carb-gear-drat-disp-hp-1)
summary(mpg.lm3)
mpg.lm4 <- lm(data = mtcars,
formula = mpg ~ wt + qsec + am - 1 + am*wt)
summary(mpg.lm4)
# when we plot the
mpg.lm4 <- lm(data = mtcars,
formula = mpg ~ wt + qsec + am - 1 + am*wt)
summary(mpg.lm4)
# when we plot the
mpg.lm4 <- lm(data = mtcars,
formula = mpg ~ wt + qsec + am - 1 + am*wt)
par()
mpg.lm3 <- lm(data = mtcars,
formula = mpg ~ .-cyl-vs-carb-gear-drat-disp-hp-1)
summary(mpg.lm3)
# when we plot the
mpg.lm4 <- lm(data = mtcars,
formula = mpg ~ wt + qsec + am - 1 + am*wt)
summary(mpg.lm4)
summary(mpg.lm3)
summary(mpg.lm4)
-2.1999-4.1312
15.4306/4.1312
min(mtcars$wt)
15.43-4.1312*1.513
max(mtcars$wt)
15.43-4.1312*5.424
predict(mpg.lm3,data.frame(am = c(0,1), wt = c(1.513,1.513),qsec = c(1,1)))
data.frame(am = c(0,1), wt = c(1.513,1.513),qsec = c(1,1)
)
test <- mtcars[2,]
test
test <- mtcars[1:2,]
test
test$wt = 1.513
test
test$qsec = 15
test[1,"am"]= 0
test
predict(mpg.lm3,test)
summary(mpg.lm3)
summary(mpg.lm4)
predict(mpg.lm4,test)
17.6+9
library(AppliedPredictiveModeling)
install.packages("caret")
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzhemerDisease)
head(AlzheimerDisease)
data(AlzheimerDisease)
rm(list = ls())
data(AlzheimerDisease)
head(predictors)
adData <- data.frame(diagnosis,predictors)
trainIndex <- createDataPartition(diagnosis, p = 0.50)
trainIndex <- createDataPartition(diagnosis
, p = 0.50
,list = F)
training = adData[trainIndex,]
test = adData[-trainIndex,]
# Question 2
rm(list = ls())
data("concrete")
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[inTrain,]
testing <- mixtures[-inTrain,]
ggplot(data = mixtures, mapping = aes(x = inTrain, y = CompressiveStrength))+
geom_point()
ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength))+
geom_point()
?hmisc
# Question 2
rm(list = ls())
# Question 1
library(caret)
library(AppliedPredictiveModeling)
data("concrete")
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[inTrain,]
testing <- mixtures[-inTrain,]
str(concrete)
install.packages("Hmisc")
# Question 2
library(Hmisc)
?cut2
ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength))+
geom_point()
ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength))+
geom_point(color = cut2(BlastFurnaceSlag))
ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength))+
geom_point(color = BlastFurnaceSlag)
ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength))+
geom_point(color =  Age)
ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = Age))+
geom_point()
library(gridExtra)
P1 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = Age))+
geom_point()
P1 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color =Cement))+
geom_point()
P2 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = BlastFurnaceSlag))+
geom_point()
P3 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = FlyAsh))+
geom_point()
P4 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = Water))+
geom_point()
P5 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = Superplasticizer))+
geom_point()
P6 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = CoarseAggregate))+
geom_point()
P7 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = FineAggregate))+
geom_point()
P8 <- ggplot(data = training, mapping = aes(x = inTrain, y = CompressiveStrength,color = Age))+
geom_point()
grid.arrange(P1,P2,P3,P4,P5,P6,P7,P8)
#Question 3
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, mapping = aes(x = SuperPlasticizer)) +
geom_density()
ggplot(data = training, mapping = aes(x = SuperPlasticizer)) +
geom_density()
head(training)
ggplot(data = training, mapping = aes(x = Superplasticizer)) +
geom_density()
summary(training)
log(0)
log(0)
# Question 4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
# Question 4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
?grep
grepl(names(training),"^IL")
grepl("^IL","ILUSION")
grepl("^IL","BILUSION")
grepl("^IL",names(training))
predictors <- names(training)[ grep("^IL",names(training))]
prdictors
predictors
?preProcess
library(caret)
preProcess
?preProcess
library(caret)
library(AppliedPredictiveModeling)
data(concrete)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
test <- createDataPartition(mixtures$CompressiveStrength, p = 3/4)
modelFit <- train(CompressiveStrength ~., data = training, method = "glm")
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[inTrain,]
testing <- mixtures[-inTrain,]
modelFit <- train(CompressiveStrength ~., data = training, method = "glm")
warnings()
?train
modelFit <- train(CompressiveStrength ~., data = training, method = "glm", family = Binomial)
m1 <- glm(formula = CompressiveStrength ~., data = training, family = binomial)
m1 <- glm(formula = CompressiveStrength ~., data = training, family = Gaussian)
?glm
m1 <- glm(formula = CompressiveStrength ~., data = training, family = gaussian)
modelFit <- train(CompressiveStrength ~., data = training, method = "glm", family = gaussian)
m1 <- glm(formula = CompressiveStrength ~., data = training, family = poisson)
m1 <- glm(formula = CompressiveStrength ~., data = training, family = gaussian)
summary(m1)
modelFit
modelFit$finalModel
summary(m1)
modelFit$modelInfo
library(caret)
install.packages("kernlab")
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = .75, list = FALSE)
inTrain <- createDataPartition(y = spam$type, p = .75, list = FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
library(caret)
library(kernlab)
data(spam)
inTrain <- createDataPartition(y = spam$type, p = .75, list = FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~., data = training, method = "glm")
set.seed(32343)
modelFit <- train(type ~., data = training, method = "glm")
install.packages("e1071")
set.seed(32343)
modelFit <- train(type ~., data = training, method = "glm")
modelFit
set.seed(32323)
folds <- createFolds(y = spam$type, k = 10, list = TRUE, returnTrain = TRUE)
sapply(folds,length)
folds[[1]][1:10]
folds[[3]][1:10]
# Question 4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
predictors <- names(training)[ grep("^IL",names(training))]
subAlz <- AlzheimerDisease[,predictors]
subAlz <- adData[,predictors]
head(subAlz)
prComp <- prcomp(subAlz)
prComp
prComp$rotation
plot(prComp$x[,1],proComp$x[,2])
prComp <- prcomp(subAlz)
prComp$rotation
plot(prComp$x[,1],proComp$x[,2])
plot(prComp$x[,1],prComp$x[,2])
plot(prComp$x[,1],prComp$x[,2], col = typeColor)
plot(prComp$x[,1],prComp$x[,2])
preProc <- preProcess(adData[,predictors], method = "pca")
AlzPC <- predict(preProc,adData[,predictors])
library(MASS)
library(randomForest)
library(tidyverse)
library(boot)
library(caret)
library(rattle)
# Read in Data
Temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",Temp)
Training <- read.csv(Temp)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",Temp)
Testing <- read.csv(Temp)
unlink(Temp)
#choose basic measurements as the predictors
{predictors <- c("roll_belt",
"pitch_belt",
"yaw_belt",
"total_accel_belt",
"gyros_belt_x",
"gyros_belt_y",
"gyros_belt_z",
"accel_belt_x",
"accel_belt_y",
"accel_belt_z",
"magnet_belt_x",
"magnet_belt_y",
"magnet_belt_z",
"roll_arm",
"pitch_arm",
"yaw_arm",
"total_accel_arm",
"gyros_arm_x",
"gyros_arm_y",
"gyros_arm_z",
"accel_arm_x",
"accel_arm_y",
"accel_arm_z",
"magnet_arm_x",
"magnet_arm_y",
"magnet_arm_z",
"roll_forearm",
"pitch_forearm",
"yaw_forearm",
"total_accel_forearm",
"gyros_forearm_x",
"gyros_forearm_y",
"gyros_forearm_z",
"accel_forearm_x",
"accel_forearm_y",
"accel_forearm_z",
"magnet_forearm_x",
"magnet_forearm_y",
"magnet_forearm_z",
"roll_dumbbell",
"pitch_dumbbell",
"yaw_dumbbell",
"total_accel_dumbbell",
"gyros_dumbbell_x",
"gyros_dumbbell_y",
"gyros_dumbbell_z",
"accel_dumbbell_x",
"accel_dumbbell_y",
"accel_dumbbell_z",
"magnet_dumbbell_x",
"magnet_dumbbell_y",
"magnet_dumbbell_z")
}
Training <- Training[,c(predictors,"classe")]
Training$classe <- factor(Training$classe)
Testing <- Testing[,c(predictors,"problem_id")]
# Exploratory Analysis
featurePlot(x = Training[,1:5],
y = Training$classe,
plot = "density",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3))
names(Testing)
# Exploratory Analysis
featurePlot(x = Training[,1:13],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3))
# Exploratory Analysis
featurePlot(x = Training[,1:9],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
# Exploratory Analysis
{
featurePlot(x = Training[,1:9],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,10:18],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,19:27],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,28:36],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,37:45],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,46:52],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
}
featurePlot(x = Training[,1:9],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,10:18],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,19:27],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,28:36],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,37:45],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
featurePlot(x = Training[,46:52],
y = Training$classe,
plot = "box",
scales = list(x = list(relation = "free"),
y = list(relation = "free")),
adjust = 1.5,
pch = "|",
auto.key = list(columns = 3),
layout = c(3,3))
modelFit <- train(classe ~., data = Training, method = "rpart")
plot(modelFit)
plot(modelFit$finalModel)
text(modelFit$finalModel, use.n = TRUE)
plot(modelFit$finalModel)
text(modelFit$finalModel, pretty = T, all = TRUE, use.n = TRUE)
fancyRpartPlot(modelFit$finalModel)
plot(modelFit$finalModel)
text(modelFit$finalModel, pretty = T, all = TRUE, use.n = TRUE)
summary(modelFit$finalModel)
install.packages("shiny")
library(shiny)
runApp('C:/Users/peted/Desktop/Data_Science/Data Products/HereWeGo')
runApp()
getwd()
ls
setwd("C:/Users/peted/Desktop/Data_Science/Data Products/HereWeGo")
runApp()
shiny::runApp()
